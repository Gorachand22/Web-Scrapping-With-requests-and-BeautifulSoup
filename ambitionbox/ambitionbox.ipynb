{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if response code is 403\n",
    " - headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    " -requests.get('url',headers=headers).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    "name = 'data scientist'\n",
    "webpage=requests.get(f'https://www.ambitionbox.com/jobs/search?tag={name}&page=1', headers=headers).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may be the name of a specific parser \n",
    "# (e.g.(\"lxml\", \"lxml-xml\", \"html.parser\", or \"html5lib\") \n",
    "# or it may be the type of markup to be used (\"html\", \"html5\", \"xml\")\n",
    "soup1 = bs(webpage,\"lxml\")\n",
    "\n",
    "print(soup1.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> Jobs February 2024 | AmbitionBox</title>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup1.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'data scientist'\n",
    "try:\n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    "    webpage=requests.get(f'https://www.ambitionbox.com/jobs/search?tag={name}', headers=headers).text\n",
    "    soup = bs(webpage,\"lxml\")\n",
    "    page = soup.find_all('div',class_=\"col-left jdDesktop\")[0].find_all('div',class_=\"jobsInfoCardCont\")\n",
    "    data_number = str(soup.find_all('h1', class_=\"container jobs-h1 bold-title-l\")[0].text.strip().split('\\n')[0])\n",
    "    data_number = int(data_number.replace(',',''))\n",
    "\n",
    "except:\n",
    "    data_number = 0\n",
    "    \n",
    "if data_number > 0:\n",
    "    if data_number%10 == 0:\n",
    "        last_page = data_number//10\n",
    "    else:\n",
    "        last_page = data_number//10 + 1\n",
    "else:\n",
    "    last_page = 0\n",
    "last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "title = []\n",
    "company = []\n",
    "rating = []\n",
    "review = []\n",
    "img = []\n",
    "location = []\n",
    "experience = []\n",
    "\n",
    "if last_page > 0:\n",
    "    \n",
    "    for i in range(1,last_page+1):\n",
    "        url = f'https://www.ambitionbox.com/jobs/search?tag={name}&page={i}'\n",
    "        webpage=requests.get(url, headers=headers).text\n",
    "        soup = bs(webpage,\"lxml\")\n",
    "        page = soup.find_all('div',class_=\"col-left jdDesktop\")[0].find_all('div',class_=\"jobsInfoCardCont\")\n",
    "        flag = len(page)\n",
    "        if flag >0:\n",
    "            for j in range(flag):\n",
    "                    try:\n",
    "                        title.append(page[j].div.div['title'].strip())\n",
    "                    except:\n",
    "                        title.append('Not found')\n",
    "\n",
    "                    try:\n",
    "                        company.append(page[j].find('p', class_=\"company body-medium\")['title'].strip())\n",
    "                    except:\n",
    "                        company.append('Not found')\n",
    "                    \n",
    "                    try:\n",
    "                        rating .append(page[j].find('div', class_ = \"rating-wrapper\").a.span.string)\n",
    "                    except:\n",
    "                        rating .append('Not found')\n",
    "                    \n",
    "                    try:\n",
    "                        review .append(page[j].find('div', class_=\"rating-wrapper\").find('a', class_ = \"review-count caption-strong-medium\").string.strip().split('\\n')[0][1:])\n",
    "                    except:\n",
    "                        review .append('Not found')\n",
    "                    \n",
    "                    try:\n",
    "                        img .append(page[j].find('div', class_ = 'img').img['src'])\n",
    "                    except:\n",
    "                        img .append('Not found')\n",
    "                    \n",
    "                    try:\n",
    "                        location .append(page[j].find('div', class_ = \"other-info\").find('div', class_ = \"entity loc\").text.strip())\n",
    "                    except:\n",
    "                        location .append('Not found')\n",
    "                    \n",
    "                    try:\n",
    "                        experience .append(page[j].find('div', class_ = \"entity\").text.strip())\n",
    "                    except:\n",
    "                        experience .append('Not found')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "df = pd.DataFrame({'img':img,'title':title,'company':company,'rating':rating,'review':review, 'location':location,'experience':experience})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2651, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('job.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
